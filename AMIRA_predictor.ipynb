{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statistics\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "from matplotlib import pyplot\n",
    "from statsmodels.tsa.arima_model import ARIMA \n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>AS14.01</td>\n",
       "      <td>2014-02-26 13:00:00.000</td>\n",
       "      <td>mood</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>AS14.01</td>\n",
       "      <td>2014-02-26 15:00:00.000</td>\n",
       "      <td>mood</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>AS14.01</td>\n",
       "      <td>2014-02-26 18:00:00.000</td>\n",
       "      <td>mood</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>AS14.01</td>\n",
       "      <td>2014-02-26 21:00:00.000</td>\n",
       "      <td>mood</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>AS14.01</td>\n",
       "      <td>2014-02-27 09:00:00.000</td>\n",
       "      <td>mood</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       id                     time variable  value\n",
       "0           1  AS14.01  2014-02-26 13:00:00.000     mood    6.0\n",
       "1           2  AS14.01  2014-02-26 15:00:00.000     mood    6.0\n",
       "2           3  AS14.01  2014-02-26 18:00:00.000     mood    6.0\n",
       "3           4  AS14.01  2014-02-26 21:00:00.000     mood    7.0\n",
       "4           5  AS14.01  2014-02-27 09:00:00.000     mood    6.0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read file\n",
    "df_data = pd.read_csv(\"data/dataset_mood_smartphone.csv\")\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_day=\"2014-02-26\"\n",
    "new_data=pd.DataFrame(columns=['id', 'time', 'var',\"value\"])\n",
    "temp_list=[]\n",
    "for index, row in df_data.iterrows():\n",
    "    date=row[\"time\"].split(\" \")[0]\n",
    "    if date != prev_day:\n",
    "        new_data.loc[index]=[df_data.loc[index-1][\"id\"], prev_day , df_data.loc[index-1][\"variable\"], statistics.mean(temp_list)]\n",
    "        temp_list=[row[\"value\"]]\n",
    "    else:\n",
    "        temp_list.append(row[\"value\"])\n",
    "    prev_day=date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "      <th>var</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AS14.01</td>\n",
       "      <td>2014-02-26</td>\n",
       "      <td>mood</td>\n",
       "      <td>6.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AS14.01</td>\n",
       "      <td>2014-02-27</td>\n",
       "      <td>mood</td>\n",
       "      <td>6.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AS14.01</td>\n",
       "      <td>2014-03-21</td>\n",
       "      <td>mood</td>\n",
       "      <td>6.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>AS14.01</td>\n",
       "      <td>2014-03-22</td>\n",
       "      <td>mood</td>\n",
       "      <td>6.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>AS14.01</td>\n",
       "      <td>2014-03-23</td>\n",
       "      <td>mood</td>\n",
       "      <td>6.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>AS14.01</td>\n",
       "      <td>2014-03-24</td>\n",
       "      <td>mood</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>AS14.01</td>\n",
       "      <td>2014-03-25</td>\n",
       "      <td>mood</td>\n",
       "      <td>6.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>AS14.01</td>\n",
       "      <td>2014-03-26</td>\n",
       "      <td>mood</td>\n",
       "      <td>6.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>AS14.01</td>\n",
       "      <td>2014-03-27</td>\n",
       "      <td>mood</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>AS14.01</td>\n",
       "      <td>2014-03-28</td>\n",
       "      <td>mood</td>\n",
       "      <td>6.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>AS14.01</td>\n",
       "      <td>2014-03-29</td>\n",
       "      <td>mood</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>AS14.01</td>\n",
       "      <td>2014-03-30</td>\n",
       "      <td>mood</td>\n",
       "      <td>7.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>AS14.01</td>\n",
       "      <td>2014-03-31</td>\n",
       "      <td>mood</td>\n",
       "      <td>7.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>AS14.01</td>\n",
       "      <td>2014-04-01</td>\n",
       "      <td>mood</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>AS14.01</td>\n",
       "      <td>2014-04-02</td>\n",
       "      <td>mood</td>\n",
       "      <td>6.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>AS14.01</td>\n",
       "      <td>2014-04-03</td>\n",
       "      <td>mood</td>\n",
       "      <td>6.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>AS14.01</td>\n",
       "      <td>2014-04-04</td>\n",
       "      <td>mood</td>\n",
       "      <td>6.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>AS14.01</td>\n",
       "      <td>2014-04-05</td>\n",
       "      <td>mood</td>\n",
       "      <td>6.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>AS14.01</td>\n",
       "      <td>2014-04-06</td>\n",
       "      <td>mood</td>\n",
       "      <td>6.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>AS14.01</td>\n",
       "      <td>2014-04-07</td>\n",
       "      <td>mood</td>\n",
       "      <td>6.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>AS14.01</td>\n",
       "      <td>2014-04-08</td>\n",
       "      <td>mood</td>\n",
       "      <td>6.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>AS14.01</td>\n",
       "      <td>2014-04-09</td>\n",
       "      <td>mood</td>\n",
       "      <td>7.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>AS14.01</td>\n",
       "      <td>2014-04-10</td>\n",
       "      <td>mood</td>\n",
       "      <td>7.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>AS14.01</td>\n",
       "      <td>2014-04-11</td>\n",
       "      <td>mood</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>AS14.01</td>\n",
       "      <td>2014-04-12</td>\n",
       "      <td>mood</td>\n",
       "      <td>7.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>AS14.01</td>\n",
       "      <td>2014-04-13</td>\n",
       "      <td>mood</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>AS14.01</td>\n",
       "      <td>2014-04-14</td>\n",
       "      <td>mood</td>\n",
       "      <td>7.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>AS14.01</td>\n",
       "      <td>2014-04-15</td>\n",
       "      <td>mood</td>\n",
       "      <td>6.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>AS14.01</td>\n",
       "      <td>2014-04-16</td>\n",
       "      <td>mood</td>\n",
       "      <td>7.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>AS14.01</td>\n",
       "      <td>2014-04-17</td>\n",
       "      <td>mood</td>\n",
       "      <td>6.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376848</th>\n",
       "      <td>AS14.28</td>\n",
       "      <td>2014-04-12</td>\n",
       "      <td>appCat.weather</td>\n",
       "      <td>14.090333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376850</th>\n",
       "      <td>AS14.28</td>\n",
       "      <td>2014-04-13</td>\n",
       "      <td>appCat.weather</td>\n",
       "      <td>53.429500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376852</th>\n",
       "      <td>AS14.28</td>\n",
       "      <td>2014-04-14</td>\n",
       "      <td>appCat.weather</td>\n",
       "      <td>33.129000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376853</th>\n",
       "      <td>AS14.28</td>\n",
       "      <td>2014-04-15</td>\n",
       "      <td>appCat.weather</td>\n",
       "      <td>43.824000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376855</th>\n",
       "      <td>AS14.28</td>\n",
       "      <td>2014-04-16</td>\n",
       "      <td>appCat.weather</td>\n",
       "      <td>39.618000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376857</th>\n",
       "      <td>AS14.28</td>\n",
       "      <td>2014-04-18</td>\n",
       "      <td>appCat.weather</td>\n",
       "      <td>35.589000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376859</th>\n",
       "      <td>AS14.28</td>\n",
       "      <td>2014-04-19</td>\n",
       "      <td>appCat.weather</td>\n",
       "      <td>11.094000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376860</th>\n",
       "      <td>AS14.28</td>\n",
       "      <td>2014-04-21</td>\n",
       "      <td>appCat.weather</td>\n",
       "      <td>39.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376863</th>\n",
       "      <td>AS14.28</td>\n",
       "      <td>2014-04-22</td>\n",
       "      <td>appCat.weather</td>\n",
       "      <td>14.918667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376865</th>\n",
       "      <td>AS14.28</td>\n",
       "      <td>2014-04-23</td>\n",
       "      <td>appCat.weather</td>\n",
       "      <td>26.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376869</th>\n",
       "      <td>AS14.28</td>\n",
       "      <td>2014-04-24</td>\n",
       "      <td>appCat.weather</td>\n",
       "      <td>32.641250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376873</th>\n",
       "      <td>AS14.28</td>\n",
       "      <td>2014-04-25</td>\n",
       "      <td>appCat.weather</td>\n",
       "      <td>15.677500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376878</th>\n",
       "      <td>AS14.28</td>\n",
       "      <td>2014-04-26</td>\n",
       "      <td>appCat.weather</td>\n",
       "      <td>20.911400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376887</th>\n",
       "      <td>AS14.28</td>\n",
       "      <td>2014-04-27</td>\n",
       "      <td>appCat.weather</td>\n",
       "      <td>18.930222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376888</th>\n",
       "      <td>AS14.28</td>\n",
       "      <td>2014-05-01</td>\n",
       "      <td>appCat.weather</td>\n",
       "      <td>40.242000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376889</th>\n",
       "      <td>AS14.28</td>\n",
       "      <td>2014-05-03</td>\n",
       "      <td>appCat.weather</td>\n",
       "      <td>43.930000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376891</th>\n",
       "      <td>AS14.28</td>\n",
       "      <td>2014-05-04</td>\n",
       "      <td>appCat.weather</td>\n",
       "      <td>15.042000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376893</th>\n",
       "      <td>AS14.28</td>\n",
       "      <td>2014-05-05</td>\n",
       "      <td>appCat.weather</td>\n",
       "      <td>26.735000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376894</th>\n",
       "      <td>AS14.28</td>\n",
       "      <td>2014-05-06</td>\n",
       "      <td>appCat.weather</td>\n",
       "      <td>31.711000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376896</th>\n",
       "      <td>AS14.28</td>\n",
       "      <td>2014-05-07</td>\n",
       "      <td>appCat.weather</td>\n",
       "      <td>4.593000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376898</th>\n",
       "      <td>AS14.30</td>\n",
       "      <td>2014-03-23</td>\n",
       "      <td>appCat.weather</td>\n",
       "      <td>183.468500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376899</th>\n",
       "      <td>AS14.30</td>\n",
       "      <td>2014-03-24</td>\n",
       "      <td>appCat.weather</td>\n",
       "      <td>15.070000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376900</th>\n",
       "      <td>AS14.30</td>\n",
       "      <td>2014-03-26</td>\n",
       "      <td>appCat.weather</td>\n",
       "      <td>6.087000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376901</th>\n",
       "      <td>AS14.30</td>\n",
       "      <td>2014-03-30</td>\n",
       "      <td>appCat.weather</td>\n",
       "      <td>1.007000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376904</th>\n",
       "      <td>AS14.30</td>\n",
       "      <td>2014-04-06</td>\n",
       "      <td>appCat.weather</td>\n",
       "      <td>32.501667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376907</th>\n",
       "      <td>AS14.30</td>\n",
       "      <td>2014-04-07</td>\n",
       "      <td>appCat.weather</td>\n",
       "      <td>24.962000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376908</th>\n",
       "      <td>AS14.30</td>\n",
       "      <td>2014-04-11</td>\n",
       "      <td>appCat.weather</td>\n",
       "      <td>8.032000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376909</th>\n",
       "      <td>AS14.30</td>\n",
       "      <td>2014-04-19</td>\n",
       "      <td>appCat.weather</td>\n",
       "      <td>3.008000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376910</th>\n",
       "      <td>AS14.30</td>\n",
       "      <td>2014-04-26</td>\n",
       "      <td>appCat.weather</td>\n",
       "      <td>7.026000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376911</th>\n",
       "      <td>AS14.30</td>\n",
       "      <td>2014-04-27</td>\n",
       "      <td>appCat.weather</td>\n",
       "      <td>23.033000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15518 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id        time             var       value\n",
       "4       AS14.01  2014-02-26            mood    6.250000\n",
       "7       AS14.01  2014-02-27            mood    6.333333\n",
       "12      AS14.01  2014-03-21            mood    6.200000\n",
       "17      AS14.01  2014-03-22            mood    6.400000\n",
       "22      AS14.01  2014-03-23            mood    6.800000\n",
       "27      AS14.01  2014-03-24            mood    6.000000\n",
       "31      AS14.01  2014-03-25            mood    6.750000\n",
       "36      AS14.01  2014-03-26            mood    6.600000\n",
       "41      AS14.01  2014-03-27            mood    7.000000\n",
       "46      AS14.01  2014-03-28            mood    6.400000\n",
       "51      AS14.01  2014-03-29            mood    8.000000\n",
       "55      AS14.01  2014-03-30            mood    7.500000\n",
       "60      AS14.01  2014-03-31            mood    7.400000\n",
       "65      AS14.01  2014-04-01            mood    6.000000\n",
       "69      AS14.01  2014-04-02            mood    6.500000\n",
       "74      AS14.01  2014-04-03            mood    6.400000\n",
       "79      AS14.01  2014-04-04            mood    6.200000\n",
       "84      AS14.01  2014-04-05            mood    6.800000\n",
       "88      AS14.01  2014-04-06            mood    6.500000\n",
       "92      AS14.01  2014-04-07            mood    6.500000\n",
       "97      AS14.01  2014-04-08            mood    6.600000\n",
       "102     AS14.01  2014-04-09            mood    7.400000\n",
       "107     AS14.01  2014-04-10            mood    7.400000\n",
       "112     AS14.01  2014-04-11            mood    7.000000\n",
       "116     AS14.01  2014-04-12            mood    7.250000\n",
       "120     AS14.01  2014-04-13            mood    8.000000\n",
       "125     AS14.01  2014-04-14            mood    7.200000\n",
       "130     AS14.01  2014-04-15            mood    6.400000\n",
       "135     AS14.01  2014-04-16            mood    7.200000\n",
       "140     AS14.01  2014-04-17            mood    6.600000\n",
       "...         ...         ...             ...         ...\n",
       "376848  AS14.28  2014-04-12  appCat.weather   14.090333\n",
       "376850  AS14.28  2014-04-13  appCat.weather   53.429500\n",
       "376852  AS14.28  2014-04-14  appCat.weather   33.129000\n",
       "376853  AS14.28  2014-04-15  appCat.weather   43.824000\n",
       "376855  AS14.28  2014-04-16  appCat.weather   39.618000\n",
       "376857  AS14.28  2014-04-18  appCat.weather   35.589000\n",
       "376859  AS14.28  2014-04-19  appCat.weather   11.094000\n",
       "376860  AS14.28  2014-04-21  appCat.weather   39.010000\n",
       "376863  AS14.28  2014-04-22  appCat.weather   14.918667\n",
       "376865  AS14.28  2014-04-23  appCat.weather   26.720000\n",
       "376869  AS14.28  2014-04-24  appCat.weather   32.641250\n",
       "376873  AS14.28  2014-04-25  appCat.weather   15.677500\n",
       "376878  AS14.28  2014-04-26  appCat.weather   20.911400\n",
       "376887  AS14.28  2014-04-27  appCat.weather   18.930222\n",
       "376888  AS14.28  2014-05-01  appCat.weather   40.242000\n",
       "376889  AS14.28  2014-05-03  appCat.weather   43.930000\n",
       "376891  AS14.28  2014-05-04  appCat.weather   15.042000\n",
       "376893  AS14.28  2014-05-05  appCat.weather   26.735000\n",
       "376894  AS14.28  2014-05-06  appCat.weather   31.711000\n",
       "376896  AS14.28  2014-05-07  appCat.weather    4.593000\n",
       "376898  AS14.30  2014-03-23  appCat.weather  183.468500\n",
       "376899  AS14.30  2014-03-24  appCat.weather   15.070000\n",
       "376900  AS14.30  2014-03-26  appCat.weather    6.087000\n",
       "376901  AS14.30  2014-03-30  appCat.weather    1.007000\n",
       "376904  AS14.30  2014-04-06  appCat.weather   32.501667\n",
       "376907  AS14.30  2014-04-07  appCat.weather   24.962000\n",
       "376908  AS14.30  2014-04-11  appCat.weather    8.032000\n",
       "376909  AS14.30  2014-04-19  appCat.weather    3.008000\n",
       "376910  AS14.30  2014-04-26  appCat.weather    7.026000\n",
       "376911  AS14.30  2014-04-27  appCat.weather   23.033000\n",
       "\n",
       "[15518 rows x 4 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.25, 6.333333333333333, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 6.2, 6.4, 6.8, 6.0, 6.75, 6.6, 7.0, 6.4, 8.0, 7.5, 7.4, 6.0, 6.5, 6.4, 6.2, 6.8, 6.5, 6.5, 6.6, 7.4, 7.4, 7.0, 7.25, 8.0, 7.2, 6.4, 7.2, 6.6, 6.8, 7.8, 7.25, 7.6, 7.4, 7.6, 7.6, 7.2, 7.6, 7.5, 7.6, 7.0, 7.8, 8.0, 7.6, 8.0, 8.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 6.333333333333333, 6.75, 8.2, 6.8, 7.25, 7.5, 6.5, 6.25, 6.4, 7.75, 7.2, 7.25, 6.8, 7.25, 7.0, 7.2, 7.4, 6.4, 5.75, 6.4, 7.4, 4.5, 6.8, 6.25, 7.25, 7.25, 6.5, 6.0, 7.2, 8.0, 7.25, 6.666666666666667, 6.5, 6.5, 5.666666666666667, 5.0, 5.5, 5.666666666666667, 5.5, 7.0, 9.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 9.0, 7.8, 8.2, 7.8, 7.8, 8.25, 7.75, 8.0, 8.6, 8.4, 7.4, 7.6, 7.4, 7.8, 7.8, 7.6, 6.8, 7.4, 7.4, 7.8, 7.4, 7.6, 7.666666666666667, 7.4, 7.0, 7.6, 8.0, 7.25, 7.5, 7.8, 7.5, 7.4, 7.6, 7.0, 7.4, 7.5, 7.5, 7.6, 7.0, 7.2, 7.0, 7.2, 7.6, 7.75, 7.4, 7.25, nan, 7.666666666666667, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 8.0, 6.2, 6.333333333333333, 6.0, 7.5, 6.75, 7.2, 7.25, 3.75, 4.4, 3.75, 5.333333333333333, 5.5, 5.8, 6.2, 6.4, 6.2, 6.8, 7.0, 7.0, 7.2, 7.0, 7.5, 6.8, 6.75, 6.75, 7.0, 7.2, 7.0, 7.0, 7.5, 6.4, 7.0, 7.2, 6.6, 7.5, 7.2, 7.2, 7.2, 7.2, 7.2, 7.2, 7.2, 7.8, 7.4, 7.0, 6.8, 7.0, 6.8, 7.0, 6.75, 7.0, 6.333333333333333, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 7.0, 7.0, 8.0, 7.0, 7.6, 7.8, 7.8, 7.0, 7.75, 6.8, 7.2, 7.0, 7.0, 7.0, 6.2, 6.6, 7.4, 7.6, 7.8, 8.2, 6.5, 7.25, 7.0, 7.6, 6.8, 6.25, 6.8, 8.2, 7.0, 6.6, 7.0, 7.75, 6.4, 7.5, 7.2, 6.75, 7.25, 6.8, 8.0, 7.2, 6.25, 7.6, 7.0, nan, 6.75, 7.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 6.8, 5.25, 7.0, 6.0, 7.75, 8.0, 7.666666666666667, 6.6, 6.8, 8.25, 7.0, 6.2, 4.333333333333333, 6.6, 5.5, 6.2, 6.5, 6.0, 6.75, 5.4, 6.8, 6.4, 6.2, 3.5, 6.4, 6.5, 6.2, 6.0, 4.75, 3.8, 5.2, 7.0, 3.0, 6.6, 6.0, 6.0, 5.6, 3.3333333333333335, 5.4, 6.0, 6.75, 5.0, 5.0, 5.0, 6.2, 5.666666666666667, 8.0, 5.5, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 6.333333333333333, 7.2, 7.4, 7.0, 7.2, 6.8, 6.6, 7.0, 6.6, 7.4, 6.4, 7.0, 5.4, 6.4, 7.0, 6.4, 6.6, 6.4, 7.2, 6.8, 7.2, 6.5, 6.333333333333333, 6.25, 7.166666666666667, 6.8, 7.6, 7.2, 6.6, 7.0, 7.5, 7.4, 7.6, 7.0, 6.5, 6.25, 7.6, 7.6, 7.0, 7.6, 6.6, 6.4, 6.6, 6.2, 6.0, 7.8, 6.4, 6.4, 6.0, 5.6, 6.666666666666667, 6.333333333333333, 6.0, 6.0, 5.8, 5.75, 6.666666666666667, 7.0, 7.2, 7.4, 6.8, 6.666666666666667, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 7.0, 7.0, 6.75, 7.25, 6.2, 7.75, 7.8, 8.25, 8.0, 7.75, 7.0, 7.6, 6.2, 7.6, 7.25, 7.5, 6.8, 6.2, 7.2, 6.5, 6.0, 6.8, 7.0, 6.0, 5.8, 6.0, 5.5, 7.0, 6.6, 8.0, 6.25, 6.5, 6.6, 6.333333333333333, 7.2, 7.25, 8.0, 6.25, 6.6, 6.75, 7.0, 7.5, 7.6, 7.75, 6.6, 6.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 5.5, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 7.0, 6.75, 6.75, 5.8, 6.4, 6.4, 6.0, 5.4, 6.5, 6.2, 6.25, 6.4, 6.25, 5.25, 6.4, 6.6, 6.8, 5.6, 6.6, 6.8, 7.0, 6.8, 6.6, 5.8, 6.4, 6.0, 6.5, 5.8, 6.6, 5.6, 7.0, 6.0, 6.6, 6.0, 6.25, 6.2, 5.5, 5.6, 4.8, 6.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 7.0, 7.8, 7.0, 6.4, 6.6, 7.0, 7.8, 6.4, 6.4, 8.4, 7.4, 8.8, 7.6, 8.4, 7.4, 7.6, 7.2, 6.2, 7.0, 7.5, 7.4, 7.6, 7.8, 6.8, 6.25, 7.4, 8.2, 7.8, 7.6, 6.8, 6.8, 6.6, 6.8, 6.0, 6.0, 6.4, 3.5, 7.2, 6.6, 7.4, 5.75, 7.4, 7.666666666666667, 7.75, 8.8, 8.0, 8.166666666666666, 8.5, 7.833333333333333, 8.333333333333334, 8.0, 7.25, 8.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 7.0, 6.4, 5.8, 6.0, 6.5, 5.75, 7.0, 6.6, 6.2, 8.0, 6.5, 6.75, 6.2, 7.0, 7.333333333333333, 7.5, 7.4, 7.4, 7.0, 6.8, 8.0, 6.666666666666667, 7.75, 7.5, nan, 7.5, 6.0, 6.0, 6.2, 6.5, 6.75, 7.5, 7.0, 7.0, 7.0, 7.333333333333333, 8.0, 8.0, 7.666666666666667, nan, nan, 7.0, 6.0, 6.666666666666667, 6.8, 6.8, 7.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 6.5, 6.75, 6.166666666666667, 6.4, 7.2, 7.4, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.2, 7.0, 7.2, 7.0, 7.4, 7.2, 7.2, 7.2, 7.2, 7.2, 7.8, 6.2, 6.8, 6.8, 7.0, 7.2, 7.0, 7.4, 7.0, 7.0, 7.0, 7.0, 6.4, 6.0, 7.0, 7.0, 7.2, 7.0, 7.0, 7.0, 7.0, 6.2, 7.0, 7.0, 7.0, 6.0, 6.6, 7.0, 6.8, 7.0, 7.0, nan, 7.0, 7.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 8.0, 7.4, 6.4, 6.6, 7.2, 6.6, 6.4, 5.666666666666667, 6.8, 6.5, 7.0, 6.4, 6.0, 5.6, 6.0, 6.5, 6.0, 5.4, 6.0, 5.8, 6.4, 6.25, 6.2, 7.0, 6.75, 7.0, 6.4, 7.2, 6.6, 7.0, 7.0, 6.4, 7.0, 6.6, 7.25, 7.0, 6.8, 7.2, 7.0, 7.25, 6.6, 7.25, 5.4, 7.2, 6.75, 7.2, 8.0, 7.0, 7.0, 7.0, 8.0, nan, 7.0, 7.333333333333333, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 7.0, 8.0, 7.25, 7.5, 7.6, 7.2, 7.333333333333333, 6.2, 6.4, 7.25, 8.0, nan, nan, nan, nan, nan, nan, 7.4, 7.4, 7.4, 7.0, 7.5, 7.2, 7.2, 7.2, 6.8, 8.0, 7.25, 7.4, 7.5, 7.2, 7.0, 7.0, 7.25, 7.0, 7.0, 7.0, 6.75, 7.2, 7.2, 7.2, 7.0, 7.0, 7.2, 7.0, 7.0, 7.0, 7.2, 7.4, 6.6, 7.25, 7.2, 7.2, 8.0, 7.2, 6.75, 7.0, 7.0, 8.0, 7.0, 7.25, nan, 7.5, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 4.666666666666667, 6.6, 7.0, 6.0, 5.5, 6.0, 6.6, 6.6, 7.4, 7.0, 7.2, 6.4, 7.6, 6.6, 7.0, 8.0, 7.25, 6.6, 6.8, 7.2, 6.75, 6.8, 7.2, 7.2, 7.0, 6.4, 6.8, 6.8, 6.8, 6.8, 7.6, 6.4, 6.8, 6.0, 6.6, 7.25, 7.75, 6.333333333333333, 6.4, 7.2, 7.0, 6.8, 7.8, 7.4, 6.6, 7.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 7.0, 7.0, 7.5, 7.6, 6.8, 6.0, 6.8, 7.0, 6.25, 7.4, 7.5, 7.0, 6.25, 6.5, 6.666666666666667, 7.0, 7.0, 7.0, 6.8, 7.25, 7.75, 7.0, 7.5, 6.8, 6.8, 6.8, 6.8, 7.2, 6.4, 6.75, 7.5, 7.6, 7.4, 6.4, 7.0, 7.0, 7.0, 7.0, 6.8, 6.8, 7.25, 7.0, 7.0, 7.2, 6.75, 7.333333333333333, 7.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 7.0, 7.0, 5.8, 6.2, 7.0, 7.0, 7.0, 7.25, 7.0, 7.5, 7.5, 7.0, 7.0, 7.0, 6.5, 7.0, 5.75, 6.6, 7.2, 7.0, 7.0, 7.75, 7.2, nan, 7.25, 7.4, 7.4, 7.6, 7.75, 7.75, 7.2, 6.2, 7.0, 7.4, 7.8, 7.5, 7.0, 7.6, 7.4, 9.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 8.0, 7.6, 7.4, 6.75, 7.0, 7.25, 7.8, 7.5, 7.2, 7.5, 6.8, 6.2, 7.6, 7.0, 6.8, 6.0, 6.333333333333333, 7.4, 7.0, 6.833333333333333, 7.5, 6.0, nan, 7.0, 7.0, 7.4, 7.0, 7.25, 7.0, 7.5, 5.2, 6.4, 7.0, 7.6, 7.2, 7.4, 7.0, 6.2, 6.6, 6.8, 7.2, 7.0, 7.0, 6.2, 6.6, 7.0, 7.4, 7.0, 6.833333333333333, 6.75, 7.8, 7.0, 7.0, 7.5, 8.0, 6.5, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]\n",
      "[6.25       6.33333333        nan ... 7.         6.8        7.        ]\n"
     ]
    }
   ],
   "source": [
    "df_mood_id = new_data.loc[(new_data['var'] == \"mood\")]\n",
    "df_time_value = df_mood_id[['id','time',\"value\"]].reset_index()\n",
    "df_time_value['time'] = pd.to_datetime(df_time_value['time'],format=\"%Y-%m-%d\")\n",
    "\n",
    "X = []\n",
    "\n",
    "id = 'AS14.01'\n",
    "prev_index = 0\n",
    "for i, row in df_time_value.iterrows():\n",
    "    delta = (df_time_value['time'].iloc[prev_index] - df_time_value['time'].iloc[i]).days\n",
    "    if delta < -1:\n",
    "        for n in range(abs(delta)-1):\n",
    "            X.append(None)\n",
    "        X.append(df_time_value['value'].iloc[i])\n",
    "    elif delta > 0:\n",
    "        for n in range(365-delta-1):\n",
    "            X.append(None)\n",
    "        X.append(df_time_value['value'].iloc[i])\n",
    "    else:\n",
    "        X.append(df_time_value['value'].iloc[i])\n",
    "    prev_index = i\n",
    "            \n",
    "print(history)\n",
    "#Set up the input for ARIMA\n",
    "# index = df_time_value[[\"time\"]].values\n",
    "# data_np = df_time_value[\"value\"].values\n",
    "series = pd.Series(X)\n",
    "X= series.values\n",
    "print(X)\n",
    "np.savetxt(\"dataset_arima.txt\", X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "ename": "MissingDataError",
     "evalue": "exog contains inf or nans",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMissingDataError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-140-3dac59992222>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m#order=(p,d,q)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mARIMA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#tunne parameters!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mmodel_fit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdisp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_fit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforecast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0myhat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\arima_model.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, start_params, trend, method, transparams, solver, maxiter, full_output, disp, callback, start_ar_lags, **kwargs)\u001b[0m\n\u001b[0;32m   1155\u001b[0m                                            \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1156\u001b[0m                                            \u001b[0mmaxiter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfull_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1157\u001b[1;33m                                            callback, start_ar_lags, **kwargs)\n\u001b[0m\u001b[0;32m   1158\u001b[0m         \u001b[0mnormalized_cov_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m  \u001b[1;31m# TODO: fix this?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1159\u001b[0m         arima_fit = ARIMAResults(self, mlefit._results.params,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\arima_model.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, start_params, trend, method, transparams, solver, maxiter, full_output, disp, callback, start_ar_lags, **kwargs)\u001b[0m\n\u001b[0;32m    944\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# estimate starting parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    945\u001b[0m             start_params = self._fit_start_params((k_ar, k_ma, k), method,\n\u001b[1;32m--> 946\u001b[1;33m                                                   start_ar_lags)\n\u001b[0m\u001b[0;32m    947\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    948\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtransparams\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# transform initial parameters to ensure invertibility\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\arima_model.py\u001b[0m in \u001b[0;36m_fit_start_params\u001b[1;34m(self, order, method, start_ar_lags)\u001b[0m\n\u001b[0;32m    560\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloglike_css\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    561\u001b[0m             \u001b[1;31m#start_params = [.1]*(k_ar+k_ma+k_exog) # different one for k?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 562\u001b[1;33m             \u001b[0mstart_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_start_params_hr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_ar_lags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    563\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransparams\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    564\u001b[0m                 \u001b[0mstart_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_invtransparams\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\arima_model.py\u001b[0m in \u001b[0;36m_fit_start_params_hr\u001b[1;34m(self, order, start_ar_lags)\u001b[0m\n\u001b[0;32m    499\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mmaxlag\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mnobs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m                         \u001b[0mmaxlag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnobs\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 501\u001b[1;33m                     \u001b[0marmod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAR\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mic\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'bic'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'nc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxlag\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmaxlag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    502\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    503\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mstart_ar_lags\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mnobs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\ar_model.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, maxlag, method, ic, trend, transparams, start_params, solver, maxiter, full_output, disp, callback, **kwargs)\u001b[0m\n\u001b[0;32m    538\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mic\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'aic'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'bic'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'hqic'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m't-stat'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    539\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ic option %s not understood\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 540\u001b[1;33m             \u001b[0mk_ar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect_order\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk_ar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mic\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    541\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    542\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mk_ar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mk_ar\u001b[0m  \u001b[1;31m# change to what was chosen by ic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\ar_model.py\u001b[0m in \u001b[0;36mselect_order\u001b[1;34m(self, maxlag, ic, trend, method)\u001b[0m\n\u001b[0;32m    431\u001b[0m                 fit = AR(endog_tmp).fit(maxlag=lag, method=method,\n\u001b[0;32m    432\u001b[0m                                         \u001b[0mfull_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrend\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 433\u001b[1;33m                                         maxiter=100, disp=0)\n\u001b[0m\u001b[0;32m    434\u001b[0m                 \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlag\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'fit.'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m             \u001b[0mbestic\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbestlag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miteritems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\ar_model.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, maxlag, method, ic, trend, transparams, start_params, solver, maxiter, full_output, disp, callback, **kwargs)\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"cmle\"\u001b[0m\u001b[1;33m:\u001b[0m     \u001b[1;31m# do OLS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m             \u001b[0marfit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOLS\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    556\u001b[0m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marfit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnobs\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mk_ar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\regression\\linear_model.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m    815\u001b[0m                  **kwargs):\n\u001b[0;32m    816\u001b[0m         super(OLS, self).__init__(endog, exog, missing=missing,\n\u001b[1;32m--> 817\u001b[1;33m                                   hasconst=hasconst, **kwargs)\n\u001b[0m\u001b[0;32m    818\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m\"weights\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_keys\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    819\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_keys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"weights\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\regression\\linear_model.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, endog, exog, weights, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m    661\u001b[0m             \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    662\u001b[0m         super(WLS, self).__init__(endog, exog, missing=missing,\n\u001b[1;32m--> 663\u001b[1;33m                                   weights=weights, hasconst=hasconst, **kwargs)\n\u001b[0m\u001b[0;32m    664\u001b[0m         \u001b[0mnobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    665\u001b[0m         \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\regression\\linear_model.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[0;32m    177\u001b[0m     \"\"\"\n\u001b[0;32m    178\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 179\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRegressionModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    180\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data_attr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'pinv_wexog'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wendog'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wexog'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'weights'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLikelihoodModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    213\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[0mhasconst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'hasconst'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         self.data = self._handle_data(endog, exog, missing, hasconst,\n\u001b[1;32m---> 64\u001b[1;33m                                       **kwargs)\n\u001b[0m\u001b[0;32m     65\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mk_constant\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mk_constant\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexog\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexog\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py\u001b[0m in \u001b[0;36m_handle_data\u001b[1;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_handle_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhasconst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhandle_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhasconst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[1;31m# kwargs arrays could have changed, easier to just attach here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\data.py\u001b[0m in \u001b[0;36mhandle_data\u001b[1;34m(endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m    631\u001b[0m     \u001b[0mklass\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhandle_data_class_factory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    632\u001b[0m     return klass(endog, exog=exog, missing=missing, hasconst=hasconst,\n\u001b[1;32m--> 633\u001b[1;33m                  **kwargs)\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\data.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[1;31m# this has side-effects, attaches k_constant and const_idx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_constant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhasconst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_integrity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cache\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresettable_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\data.py\u001b[0m in \u001b[0;36m_handle_constant\u001b[1;34m(self, hasconst)\u001b[0m\n\u001b[0;32m    131\u001b[0m             \u001b[0mptp_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mptp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mptp_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mMissingDataError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'exog contains inf or nans'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    134\u001b[0m             \u001b[0mconst_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mptp_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mk_constant\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconst_idx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMissingDataError\u001b[0m: exog contains inf or nans"
     ]
    }
   ],
   "source": [
    "size = int(len(X) * 0.66)\n",
    "train, test = X[0:size], X[size:len(X)]\n",
    "\n",
    "history = [x for x in train]\n",
    "predictions = list()\n",
    "for t in range(len(test)):\n",
    "    #order=(p,d,q) \n",
    "    model = ARIMA(history, order=(1,1,1))#tunne parameters!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "    model_fit = model.fit(disp=0)\n",
    "    output = model_fit.forecast()\n",
    "    yhat = output[0]\n",
    "    predictions.append(yhat)\n",
    "    obs = test[t]\n",
    "    history.append(obs)\n",
    "    print('predicted=%f, expected=%f' % (yhat, obs))\n",
    "error = mean_squared_error(test, predictions)\n",
    "print('Test MSE: %.3f' % error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02-26</td>\n",
       "      <td>6.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>02-27</td>\n",
       "      <td>6.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>03-21</td>\n",
       "      <td>6.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>03-22</td>\n",
       "      <td>6.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>03-23</td>\n",
       "      <td>6.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>03-24</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>03-25</td>\n",
       "      <td>6.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>03-26</td>\n",
       "      <td>6.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>03-27</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>03-28</td>\n",
       "      <td>6.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>03-29</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>03-30</td>\n",
       "      <td>7.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>03-31</td>\n",
       "      <td>7.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>04-01</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>04-02</td>\n",
       "      <td>6.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>04-03</td>\n",
       "      <td>6.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>04-04</td>\n",
       "      <td>6.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>04-05</td>\n",
       "      <td>6.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>04-06</td>\n",
       "      <td>6.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>04-07</td>\n",
       "      <td>6.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>04-08</td>\n",
       "      <td>6.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>04-09</td>\n",
       "      <td>7.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>04-10</td>\n",
       "      <td>7.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>04-11</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>04-12</td>\n",
       "      <td>7.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>04-13</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>04-14</td>\n",
       "      <td>7.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>04-15</td>\n",
       "      <td>6.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>04-16</td>\n",
       "      <td>7.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>04-17</td>\n",
       "      <td>6.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>04-18</td>\n",
       "      <td>6.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>04-19</td>\n",
       "      <td>7.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>04-20</td>\n",
       "      <td>7.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>04-21</td>\n",
       "      <td>7.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>04-22</td>\n",
       "      <td>7.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>04-23</td>\n",
       "      <td>7.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>04-24</td>\n",
       "      <td>7.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>04-25</td>\n",
       "      <td>7.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>04-26</td>\n",
       "      <td>7.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>04-27</td>\n",
       "      <td>7.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>04-28</td>\n",
       "      <td>7.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>04-29</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>04-30</td>\n",
       "      <td>7.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>05-01</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>05-02</td>\n",
       "      <td>7.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>05-03</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>05-04</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      time     value\n",
       "4    02-26  6.250000\n",
       "7    02-27  6.333333\n",
       "12   03-21  6.200000\n",
       "17   03-22  6.400000\n",
       "22   03-23  6.800000\n",
       "27   03-24  6.000000\n",
       "31   03-25  6.750000\n",
       "36   03-26  6.600000\n",
       "41   03-27  7.000000\n",
       "46   03-28  6.400000\n",
       "51   03-29  8.000000\n",
       "55   03-30  7.500000\n",
       "60   03-31  7.400000\n",
       "65   04-01  6.000000\n",
       "69   04-02  6.500000\n",
       "74   04-03  6.400000\n",
       "79   04-04  6.200000\n",
       "84   04-05  6.800000\n",
       "88   04-06  6.500000\n",
       "92   04-07  6.500000\n",
       "97   04-08  6.600000\n",
       "102  04-09  7.400000\n",
       "107  04-10  7.400000\n",
       "112  04-11  7.000000\n",
       "116  04-12  7.250000\n",
       "120  04-13  8.000000\n",
       "125  04-14  7.200000\n",
       "130  04-15  6.400000\n",
       "135  04-16  7.200000\n",
       "140  04-17  6.600000\n",
       "145  04-18  6.800000\n",
       "150  04-19  7.800000\n",
       "154  04-20  7.250000\n",
       "159  04-21  7.600000\n",
       "164  04-22  7.400000\n",
       "169  04-23  7.600000\n",
       "174  04-24  7.600000\n",
       "179  04-25  7.200000\n",
       "184  04-26  7.600000\n",
       "188  04-27  7.500000\n",
       "193  04-28  7.600000\n",
       "198  04-29  7.000000\n",
       "203  04-30  7.800000\n",
       "208  05-01  8.000000\n",
       "213  05-02  7.600000\n",
       "218  05-03  8.000000\n",
       "222  05-04  8.000000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_time_value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
